{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "params = {\"axes.labelsize\": 14,\n",
    "          \"axes.titlesize\": 16,}\n",
    "plt.rcParams[\"axes.linewidth\"] = 1\n",
    "plt.rcParams['mathtext.bf'] = 'STIXGeneral:italic:bold'\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "def place(ax):\n",
    "  ax.tick_params(direction=\"in\", which=\"minor\", length=3)\n",
    "  ax.tick_params(direction=\"in\", which=\"major\", length=5, labelsize=13)\n",
    "  ax.grid(which=\"major\", ls=\"dashed\", dashes=(1, 3), lw=0.8, zorder=0)\n",
    "  fig.tight_layout()\n",
    "\n",
    "\n",
    "training_data_path = \"../../../bui2026-dielectrocapillarity/training-data/\"\n",
    "simData1 = np.load(training_data_path + \"dipole_T250_T500_coswave.npy\", allow_pickle=True).item()\n",
    "simData2 = np.load(training_data_path + \"dipole_T500_coswave.npy\", allow_pickle=True).item()\n",
    "simData3 = np.load(training_data_path + \"dipole_T300_coswave.npy\", allow_pickle=True).item()\n",
    "simData4 = np.load(training_data_path + \"dipole_T500_walls.npy\", allow_pickle=True).item()\n",
    "simData5 = np.load(training_data_path + \"dipole_T250_T500_walls.npy\", allow_pickle=True).item()\n",
    "\n",
    "simData = {}\n",
    "\n",
    "for key in ['training', 'validation', 'test']:\n",
    "    combined_data = {}\n",
    "    datasets = [ simData1, simData2, simData3, simData4, simData5]\n",
    "    \n",
    "    for i, simData in enumerate(datasets, start=1):\n",
    "        for inner_key, value in simData.get(key, {}).items():\n",
    "            \n",
    "            combined_data[f\"{inner_key}_{i}\"] = value\n",
    "        \n",
    "            \n",
    "    simData[key] = combined_data\n",
    "\n",
    "def combine_data(xbins, elec, elec_grad, rho_A, mu_A, muloc_A, c1_A, n):\n",
    "    data = {}\n",
    "    \n",
    "    data = np.zeros(xbins.shape, dtype=[('xbins', 'f8'), ('elec', 'f8'), ('elec_grad', 'f8'),  ('n', 'f8'), \n",
    "                                        ('rho_A', 'f8'), ('muloc_A', 'f8'), ('c1_A_scaledT', 'f8'), ('mu_A', 'f8')])\n",
    "    \n",
    "    data['xbins'] = xbins\n",
    "    data['elec'] = elec\n",
    "    data['elec_grad'] = elec_grad\n",
    "    data['rho_A'] = rho_A\n",
    "    data['mu_A'] = mu_A\n",
    "    data['muloc_A'] = muloc_A\n",
    "    data['elec'] = elec\n",
    "    data['elec_grad'] = elec_grad\n",
    "    data['c1_A_scaledT'] = c1_A\n",
    "    data['n'] = n\n",
    "    \n",
    "    # set n to zero if all of elec is zero\n",
    "    if np.all(elec_grad == 0):\n",
    "        data['n'] = np.zeros_like(n)\n",
    "        print(\"Setting n to zero\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Combine all simulations into one list\n",
    "all_simulations = []\n",
    "for category in ['training', 'validation', 'test']:\n",
    "    all_simulations.extend(list(simData[category].keys()))\n",
    "    \n",
    "\n",
    "# Add mirror simulations\n",
    "for sim in all_simulations:\n",
    "    category = next(cat for cat in simData if sim in simData[cat])\n",
    "    data = simData[category][sim]\n",
    "    xbins = data['profiles']['xbins']\n",
    "    rho_A = data['profiles']['rho_A']\n",
    "    muloc_A = data['profiles']['muloc_A']\n",
    "    c1_A = data['profiles']['c1_A_scaledT']\n",
    "    mu_A = data['profiles']['mu_A']\n",
    "    elec = -data['profiles']['elec']\n",
    "    elec_grad = -np.flip(data['profiles']['elec_grad'])\n",
    "    n = -data['profiles']['n']\n",
    "    \n",
    "    sim_name = sim + \"_mirror\"\n",
    "    combined_data_mirror = combine_data(xbins, elec, elec_grad, rho_A, mu_A, muloc_A, c1_A, n)\n",
    "    \n",
    "    data_dict = {'profiles': {}, 'params': {}}\n",
    "    data_dict['profiles'] = combined_data_mirror\n",
    "    data_dict['params'] = data['params']\n",
    "    \n",
    "    simData[category][sim_name] = data_dict\n",
    "    \n",
    "# Add flip simulations\n",
    "for sim in all_simulations:\n",
    "    category = next(cat for cat in simData if sim in simData[cat])\n",
    "    data = simData[category][sim]\n",
    "    xbins = np.flip(data['profiles']['xbins'])\n",
    "    rho_A = np.flip(data['profiles']['rho_A'])\n",
    "    muloc_A = np.flip(data['profiles']['muloc_A'])\n",
    "    c1_A = np.flip(data['profiles']['c1_A_scaledT'])\n",
    "    mu_A = np.flip(data['profiles']['mu_A'])\n",
    "    elec = np.flip(data['profiles']['elec'])\n",
    "    elec_grad = -np.flip(data['profiles']['elec_grad'])\n",
    "    n = np.flip(data['profiles']['n'])\n",
    "    \n",
    "    sim_name = sim + \"_flip\"\n",
    "    combined_data_mirror = combine_data(xbins, elec, elec_grad, rho_A, mu_A, muloc_A, c1_A, n)\n",
    "    \n",
    "    data_dict = {'profiles': {}, 'params': {}}\n",
    "    data_dict['profiles'] = combined_data_mirror\n",
    "    data_dict['params'] = data['params']\n",
    "    \n",
    "    simData[category][sim_name] = data_dict\n",
    "\n",
    "# Combine all simulations into one list\n",
    "all_simulations = []\n",
    "for category in ['training', 'validation', 'test']:\n",
    "    all_simulations.extend(list(simData[category].keys()))\n",
    "\n",
    "print(len(all_simulations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37063c95",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aeb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random simulation\n",
    "random_sim = random.choice(all_simulations)\n",
    "#random_sim = 'sim_0954'\n",
    "\n",
    "\n",
    "category = next(cat for cat in simData if random_sim in simData[cat])\n",
    "\n",
    "data = simData[category][random_sim]\n",
    "\n",
    "z = data['profiles']['xbins']\n",
    "rho = data['profiles']['rho_A']\n",
    "muloc = data['profiles']['muloc_A']\n",
    "elec = data['profiles']['elec']\n",
    "elec_grad = data['profiles']['elec_grad']\n",
    "c1 = data['profiles']['c1_A_scaledT']\n",
    "n = data['profiles']['n']\n",
    "temp = data['params']['T']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize=(5,6), sharex='all')\n",
    "\n",
    "ax[0].plot(z, elec, label='elec', color='black')\n",
    "\n",
    "ax[0].set_ylabel(r'$e\\beta\\phi(z)$')\n",
    "ax[0].set_title(f'{random_sim} {temp}')\n",
    "\n",
    "ax[1].plot(z, rho, label='rho', color='hotpink')\n",
    "\n",
    "ax[2].plot(z, n, label='n', color='hotpink')\n",
    "\n",
    "\n",
    "ax[3].plot(z, c1, label='c1', color='hotpink')\n",
    "\n",
    "\n",
    "ax[1].set_ylabel(r'$\\rho$ [$\\mathrm{\\AA}^{-3}$]')\n",
    "\n",
    "ax[2].set_ylabel(r'$10^3 n$ [$ e\\mathrm{\\AA}^{-3}$]')\n",
    "\n",
    "\n",
    "ax[3].set_ylabel(r'$c^{(1)}$')\n",
    "ax[3].set_xlabel(r'$x$ [$\\mathrm{\\AA}$]')\n",
    "\n",
    "ax[2].set_xlim(0, 20)\n",
    "\n",
    "place(ax[1])\n",
    "place(ax[0])\n",
    "place(ax[2])\n",
    "place(ax[3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60040fd8",
   "metadata": {},
   "source": [
    "## Curate data for training, sliding window approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from data_generators import DataGeneratorThreeInput\n",
    "\n",
    "def filt(sim):\n",
    "    temp = sim[\"params\"][\"T\"]\n",
    "    return temp > 0.0\n",
    "\n",
    "# Generator options\n",
    "generatorOptions = {\n",
    "    \"batch_size\": 256,\n",
    "    \"window1Sigma\": 10.00,\n",
    "    \"window2Sigma\": 10.00,\n",
    "    \"inputKeys1\": [\"rho_A\"],\n",
    "    \"inputKeys2\": [\"elec\"],\n",
    "    \"paramsKeys\":[\"T\"],\n",
    "    \"outputKeys\": [\"n\"],\n",
    "    \"binKey\": \"xbins\",\n",
    "    \"filt\": filt,\n",
    "}\n",
    "\n",
    "# Create data generators\n",
    "trainingGenerator = DataGeneratorThreeInput(simData[\"training\"], **generatorOptions)\n",
    "validationGenerator = DataGeneratorThreeInput(simData[\"validation\"], **generatorOptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cde3e",
   "metadata": {},
   "source": [
    "## Create neural network for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf79bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define a custom layer to compute gradients of `phi` (1D array)\n",
    "@keras.utils.register_keras_serializable()\n",
    "class GradientLayer(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # Compute numerical gradient using central difference (approximated)\n",
    "        grad = 0.5 * (inputs[:, 2:] - inputs[:, :-2])  # Central difference\n",
    "        grad = tf.pad(grad, [[0, 0], [1, 1]])  # Pad to keep the same shape\n",
    "        return grad\n",
    "\n",
    "# Define the model\n",
    "profile1Inputs = {\"rho_A\": keras.Input(shape=trainingGenerator.input1Shape, name=\"rho\")}\n",
    "profile2Inputs = {\"elec\": keras.Input(shape=trainingGenerator.input2Shape, name=\"phi\")}\n",
    "paramsInputs = {\"T\": keras.Input(shape=(1,), name=\"T\")}  # Temperature input\n",
    "\n",
    "# L2 regularization\n",
    "regularizer = keras.regularizers.l2(0.0003)\n",
    "\n",
    "# Process `rho_A`\n",
    "x1 = keras.layers.Dense(256, activation=\"softplus\", kernel_regularizer=regularizer)(profile1Inputs[\"rho_A\"])\n",
    "\n",
    "# Compute gradient of `phi` using custom layer (for 1D input)\n",
    "grad_phi = GradientLayer()(profile2Inputs[\"elec\"])\n",
    "\n",
    "# Process both `phi` and its gradient\n",
    "x2_phi = keras.layers.Dense(32, activation=\"softplus\", kernel_regularizer=regularizer)(profile2Inputs[\"elec\"])\n",
    "x2_grad = keras.layers.Dense(512, activation=\"softplus\", kernel_regularizer=regularizer)(grad_phi)\n",
    "\n",
    "# Concatenate `phi` and its gradient\n",
    "x2 = keras.layers.Concatenate()([x2_phi, x2_grad])\n",
    "\n",
    "# Further process `phi` and gradient combined\n",
    "x2 = keras.layers.Dense(256, activation=\"softplus\", kernel_regularizer=regularizer)(x2)\n",
    "\n",
    "# Process `T`\n",
    "x3 = keras.layers.Dense(64, activation=\"softplus\", kernel_regularizer=regularizer)(paramsInputs[\"T\"])\n",
    "\n",
    "# Concatenate processed inputs\n",
    "x = keras.layers.Concatenate()([x1, x2, x3])\n",
    "\n",
    "# Additional Dense layers\n",
    "x = keras.layers.Dense(512, activation=\"softplus\", kernel_regularizer=regularizer)(x)\n",
    "x = keras.layers.Dense(512, activation=\"softplus\", kernel_regularizer=regularizer)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = keras.layers.Dense(trainingGenerator.outputShape[0], name=\"n\")(x)\n",
    "\n",
    "# Define Model\n",
    "model = keras.Model(inputs=(profile1Inputs | profile2Inputs | paramsInputs), outputs=outputs)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()]\n",
    ")\n",
    "\n",
    "# Print Model Summary\n",
    "model.summary()\n",
    "\n",
    "# Visualize Model\n",
    "keras.utils.plot_model(model, show_shapes=True, show_layer_names=True, show_layer_activations=True, dpi=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4e774",
   "metadata": {},
   "source": [
    "## Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e1f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import callbacks as cb\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.LearningRateScheduler(cb.lrschedule),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"../../models/n1_dipole.keras\",\n",
    "        monitor=\"val_mean_absolute_error\",\n",
    "        save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mean_absolute_error\",\n",
    "        patience=20),\n",
    "    cb.LossHistory()]\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    trainingGenerator,\n",
    "    validation_data=validationGenerator,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = keras.models.load_model(\"../../models/n1_dipole.keras\")\n",
    "model = keras.models.load_model(\"../../../bui2026-dielectrocapillarity/models/n1_dipole_Apr30.keras\")\n",
    "\n",
    "testGenerator = DataGeneratorThreeInput(simData[\"test\"], **generatorOptions)\n",
    "test_metrics = model.evaluate(testGenerator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e722dce7",
   "metadata": {},
   "source": [
    "## See the predicted correlation function of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4766b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_windows(array, bins, mode=\"wrap\"):\n",
    "\n",
    "    padded_array = np.pad(array, bins, mode=mode)\n",
    "    windows = np.empty((len(array), 2 * bins + 1))\n",
    "    for i in range(len(array)):\n",
    "        windows[i] = padded_array[i:i + 2 * bins + 1]\n",
    "    return windows\n",
    "\n",
    "\n",
    "def get_charge_density(model, density_profile, elec, params):\n",
    "    input_bins = model.input_shape[1][1]\n",
    "    window_bins = (input_bins - 1) // 2\n",
    "    rho_windows = generate_windows(density_profile, window_bins).reshape(density_profile.shape[0], input_bins, 1)\n",
    "    elec_windows = generate_windows(elec, window_bins).reshape(elec.shape[0], input_bins, 1)\n",
    "    \n",
    "    paramsInput = {key: tf.convert_to_tensor(np.full(density_profile.shape[0], value)) for key, value in params.items()}\n",
    "    return model.predict_on_batch({\"rho_A\": rho_windows, \"elec\": elec_windows, **paramsInput}).flatten()\n",
    "\n",
    "\n",
    "# Combine all tests simulations into one list\n",
    "all_test_simulations = []\n",
    "for category in ['test']:\n",
    "    all_test_simulations.extend(list(simData[category].keys()))\n",
    "\n",
    "\n",
    "# Select a random simulation\n",
    "random_sim = random.choice(all_test_simulations)\n",
    "\n",
    "# Determine which category the random simulation belongs to\n",
    "category = next(cat for cat in simData if random_sim in simData[cat])\n",
    "\n",
    "\n",
    "# Get the data for the random simulation\n",
    "data = simData[category][random_sim]\n",
    "\n",
    "# Extract z, rho, muloc, and c1\n",
    "xbins = data['profiles']['xbins']\n",
    "rho = data['profiles']['rho_A']\n",
    "muloc = data['profiles']['muloc_A']\n",
    "elec = data['profiles']['elec']\n",
    "elec_grad = data['profiles']['elec_grad']\n",
    "c1_sim = data['profiles']['c1_A_scaledT']\n",
    "n_sim = data['profiles']['n']\n",
    "temp = data['params']['T']\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(5,6), sharex='all')\n",
    "\n",
    "ax[0].plot(xbins, elec, label='phi', color='gray')\n",
    "\n",
    "ax[0].set_ylabel(r'$e\\beta\\phi(z)$')\n",
    "ax[0].set_title(f'{random_sim}, {temp}')\n",
    "\n",
    "\n",
    "ax[1].plot(xbins, rho, color='deepskyblue')\n",
    "\n",
    "\n",
    "ax[2].plot(xbins, n_sim, label='sim', color='deepskyblue', lw=2)\n",
    "\n",
    "n_pred = get_charge_density(model, rho, elec, {\"T\": temp})\n",
    "ax[2].plot(xbins, n_pred, label='predicted', color='blue', ls='--')\n",
    "\n",
    "\n",
    "ax[1].set_ylabel(r'$\\rho(z)$')\n",
    "ax[2].set_ylabel(r'$10^3 n^\\mathrm{(1)}(z)$ [$ e\\mathrm{\\AA}^{-3}$]')\n",
    "ax[2].set_xlabel(r'$z$ [$\\mathrm{\\AA}$]')\n",
    "\n",
    "ax[2].legend()\n",
    "ax[2].set_xlim(0, 20)\n",
    "ax[2].set_ylim(-10, 10)\n",
    "\n",
    "\n",
    "place(ax[0])\n",
    "place(ax[1])\n",
    "place(ax[2])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
